% 2.3, Jesús Ruiz-Ayúcar, Julio 2006
% - Sección de instalación y compilación
% 2.2, JoseMaria Cañas, abril 2005
% - énfasis en API de variables perceptivas y de control
% - desaparece implementación de servidores y del protocolo
% - nueva estructura: intro, hw+sw soportado, api de variables, aplicaciones con esquemas
% 2.0, JoseMaria Cañas, febrero 2004. 

\documentclass[a4paper,12pt,notitlepage,openany]{article}
\usepackage{url}
%\usepackage[dvips]{graphicx}
%\usepackage{graphics}
\usepackage[spanish]{babel}
%\selectlanguage{spanish}
%\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{babel}

%\usepackage{named}
\usepackage{geometry}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{hthtml}

% Espaciado por defecto, (no afecta a figuras, minipages, pie de pagina...)
\usepackage{setspace}
%\setstretch{1.35}
%\setstretch{1.2}

%para subfiguras
\usepackage[normalsize]{subfigure}
\renewcommand{\subfigtopskip}{0pt}
\renewcommand{\subfigcapskip}{0pt}
\renewcommand{\subfigbottomskip}{0pt}

% Definimos el margen y el tipo de letra de los pies de figura
\usepackage[normal,bf]{caption2}
\setlength{\captionmargin}{20pt}
\renewcommand{\captionfont}{\footnotesize\slshape}
%\newcommand{\mycaption}[1]{\caption{\textit{\small{#1}}}} 

%Para que la bibliografia salga en el indice:
\let\OLDthebibliography=\thebibliography
\def\thebibliography#1{\OLDthebibliography{#1}%
  \addcontentsline{toc}{section}{\bibname}}

\geometry{left=3cm, right=3cm, top=3cm, bottom=3cm}
%\geometry{inner=2.5cm, outer=1.5cm, top=2cm, bottom=2cm}

\makeindex

\selectlanguage{spanish}
\bibliographystyle{plain}


%\pretolerance=10000
%Para que no corte las palabras al final de la linea.

\pagestyle{headings}

\author{José M. Cañas, A. Pineda, P. Barrera, J. Ruíz-Ayucar\\
Universidad Rey Juan Carlos}
\title{Programación de robots con la plataforma jde.c}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Este manual describe el entorno \textit{jde.c} para la programación de robots. Una vez construido mecánicamente un robot móvil, toda su inteligencia reside en los programas que gobiernan su comportamiento. Cómo escribir y organizar esos programas es una cuestión compleja. La plataforma \textit{jde.c} ha sido diseñada para facilitar esa labor. En primer lugar ofrece el acceso a los sensores del robot en forma de variables que las aplicaciones leen (\textit{variables perceptivas}), y el acceso a los actuadores como variables que las aplicaciones escriben (\textit{variables de actuación}). En segundo lugar, proporciona un modelo basado en comportamientos concurrentes, llamados esquemas, para construir las aplicaciones robóticas. Se incluye en la plataforma una colección de esquemas básicos que sirven de ejemplo y están listos para ser reutilizados. Además, \textit{jde.c} ofrece soporte para el robot Pioneer con cámaras, para el simulador Stage y la posibilidad de conectarse remotamente a ellos manteniendo el acceso a través de variables. La plataforma también resuelve las necesidades de interfaz gráfica de las aplicaciones robóticas, típicamente para depuración.
\end{abstract}

%\pagenumbering{roman}
\setcounter{page}{1}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}

\tableofcontents
%\listoffigures
%\listoftables

\section{Introducción}

La robótica es una materia multidisciplinar donde confluyen muchos campos: la mecánica, la electrónica, la inteligencia artificial, el control automático e incluso la etología o la psicología. Una de las ramas más interesantes es la robótica móvil, en concreto la generación de comportamiento autónomo dentro de los robots móviles. El objetivo que persigue la robótica móvil es conseguir que las máquinas hagan tareas autónomamente con la flexibilidad y robustez que exhibe el ser humano realizándolas.

%robot=sensores+actuadores+procesadores
Hay muchos tipos de robots: con ruedas, con patas, brazos robotizados, con forma humanoide, con forma cilíndrica, etc. La morfología no es una característica esencial. Lo que identifica a cualquier robot es que combina en la misma plataforma a sensores, actuadores y procesadores. Los \textit{sensores} miden alguna característica del entorno o propia (p.e. cámaras, sensores de obstáculos, etc). Los \textit{actuadores} permiten al robot hacer algo, llevar a cabo alguna acción o simplemente desplazarse (p.e. los motores). Los \textit{procesadores} hacen los cómputos necesarios y realizan el enlace entre sensores y actuadores, materializando el comportamiento del robot en el entorno en el cual se encuentra inmerso. 

%generar inteligencia = programar al robot
%el software de robots tiene ciertas características genuinas
%programar robots != mainstream software
En la práctica, una vez construido el cuerpo mecánico del robot, el comportamiento autónomo se convierte en un problema de programación. Generar comportamiento en un robot consiste en escribir el programa que causa ese comportamiento al ejecutarse en el robot cuando éste se encuentra en cierto entorno. Sin embargo, escribir programas para robots móviles es una tarea complicada, ya que los robots son sistemas complejos. La programación de robots móviles suele ser más exigente que la creación de programas tradicionales como aplicaciones de ofimática, bases de datos, etc. 

%sensores y actuadores
%vivacidad
Por ejemplo, los programas de robots móviles están directamente conectados a la realidad física a través de sensores y actuadores. Esta situación implica que el software debe ser ágil, tomar decisiones con vivacidad para controlar correctamente a los actuadores. Por esta razón, se requiere de actuación en tiempo real, si no estricto, al menos blando.

% multitarea -> concurrencia
Una aplicación de robots móviles típicamente debe estar pendiente de varias fuentes de actividad y objetivos a la vez. El programa de un robot tiene que atender a muchas cosas simultáneamente: recoger nuevos datos de varios sensores, refrescar la interfaz gráfica, enviar periódicamente consignas a los motores, enviar o recibir datos por la red a otro proceso de la aplicación, etc. Por ello estas aplicaciones suelen ser concurrentes, lo cual les añade cierta complejidad. 

%heterogeneidad, no hay un escenario nítido
Además, los programadores de robots se enfrentan a una creciente heterogeneidad que dificulta su tarea. En cuanto al hardware, existe una gran diversidad de dispositivos sensoriales y de actuación, y por lo tanto de interfaces. El programador debe dominarlos para acceder a ellos desde las aplicaciones. Por otro lado, mientras que en muchos campos de la informática sí hay bibliotecas que un programador puede emplear para construir su propio programa, en el software de robots no hay un marco homogéneo ni hay estándares que propicien la reutilización de código \cite{utz02,montemerlo03,cote04} y la integración. En robótica cada aplicación prácticamente ha de construirse desde cero para cada robot concreto.

\subsection{Robots y entornos de programación}

%programación ad-hoc
Antiguamente los programas de control de robots se solían construir empleando directamente los \textit{drivers} para acceder a sus sensores y actuadores. Como muestra la figura \ref{fig:progjde}, el programa recogía las medidas obtenidas por los sensores y ordenaba los comandos de movimiento a los motores invocando las funciones de librería que ofrecía el fabricante en sus \textit{drivers}.

\begin{figure}[htb]
\begin{center}
\begin{tabular}{c@{\hspace*{2.cm}}c}
\includegraphics[width=6cm]{figs/programacion3} &
\includegraphics[width=6cm]{figs/programacion2}\\
\end{tabular}
\end{center}
\caption{Programación clásica de robots sobre \textit{drivers} específicos de sensores y actuadores, y programación sobre una plataforma de desarrollo}
\label{fig:progjde}
\end{figure}

Actualmente las aplicaciones con robots presentan cada vez mayor complejidad y ofrecen mayor funcionalidad. En muchos campos del software se ha ido implantando \textit{middleware} que simplifica el desarrollo de nuevas aplicaciones en esas áreas. Este \textit{middleware} proporciona contextos nítidos, estructuras de datos predefinidas, bloques muy depurados de código de uso frecuente, protocolos estándar de comunicaciones, mecanismos de sincronización, etc.. Del mismo modo, a medida que el desarrollo de software para robots móviles ha ido madurando han ido apareciendo diferentes plataformas \textit{middleware} \cite{utz02}.

Hoy en día los fabricantes más avanzados incluyen plataformas de desarrollo para simplificar a los usuarios la programación de \textit{sus} robots. Por ejemplo, ActivMedia ofrece la plataforma ARIA \cite{activmedia02} para sus robots Pioneer, PeopleBot, etc.; iRobot ofrecía Mobility \cite{rwi99} para sus B14 y B21; Evolution Robotics vende su plataforma ERSP; y Sony ofrece OPEN-R \cite{martin04} para sus Aibo.
% Otros fabricantes menos avanzados carecen de plataforma de desarrollo
% u ofrecen una muy limitada.
Además de los fabricantes, muchos grupos de investigación han creado sus propias plataformas de desarrollo. Varios ejemplos son la suite de navegación \htlink{CARMEN}{http://www-2.cs.cmu.edu/~carmen} \cite{montemerlo03} de Carnegie Mellon University, Orocos \cite{bruyninckx01}, \texttt{Player/Stage/Gazebo} (PSG) \cite{gerkey03,vaughan03}, Miro \cite{utz02}, JDE \cite{canas02}, MARIE \cite{cote04}, etc..
%Mientras los fabricantes buscan que su plataforma sirva para sus modelos, los grupos de investigación aspiran a una mayor universalidad y sus plataformas tratan de incluir soporte para los robots de sus laboratorios, típicamente de diferentes fabricantes.

%objetivos de la plataforma
El objetivo fundamental de estas plataformas es hacer más sencilla la creación de aplicaciones para robots y ocultar o atenuar la heterogeneidad ya mencionada. Hemos identificado varias características comúnes entre ellas: uniforman y simplifican el acceso al hardware, ofrecen una arquitectura software concreta y proporcionan un conjunto de bibliotecas o módulos con funciones de uso común en robótica que el cliente puede reutilizar para programar sus propias aplicaciones.

\subsection{Plataforma jde.c}
%vistazo global a toda la plataforma

Una de esas plataformas es \textit{jde.c}, fruto de una tesis doctoral sobre generación de comportamientos autónomos en robots móviles \cite{canas03}. Históricamente surge en 1997 y desde entonces ha ido evolucionando e incorporando nuevas funcionalidades. Hoy día es una plataforma de referencia para la investigación del grupo de Robótica-URJC y para la docencia de robótica en la Universidad Rey Juan Carlos. 

\subsubsection{Acceso a los sensores y actuadores}
%acceso a los sensores y actuadores
En cuanto al acceso a sensores y actuadores, \textit{jde.c} ofrece un conjunto de variables perceptivas y de actuación respectivamente. La aplicación robótica obtiene las últimas observaciones sensoriales leyendo las variables perceptivas, que la plataforma mantiene permanentemente actualizadas. La aplicación robótica ordena comandos a los motores escribiendo en las variables de actuación, que la plataforma se encarga de materializar y hacer llegar hasta los actuadores correspondientes. La plataforma \textit{jde.c} mantiene activo este interfaz de variables y la aplicación robótica se sitúa encima, leyendo continuamente los datos sensoriales de ese API y escribiendo en él los comandos motores que determina en cada momento. Este API de variables contrasta con la abstracción funcional de otras plataformas. En la seccion \ref{sec:variables} detallaremos el conjunto concreto de variables perceptivas y de actuación para el robot de referencia y su significado físico.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=9cm]{figs/jdebasico}
\end{center}
\caption{Programación sobre jde.c}
\label{fig:jdeglobal}
\end{figure}

%fuentes del hardware
Esas variables han de conectarse a los dispositivos del robot, ya sean reales o simulados. Esta conexión se determina en un fichero de configuración que especifica donde está la fuente final las variables perceptivas y el destino final de las variables de actuación. Esto permite ejecutar literalmente la misma aplicación dentro del mundo real o del simulador sin más que cambiar ese fichero de configuración de una ejecución a otra. 

Como ilustra la figura \ref{fig:jdeglobal}, \textit{jde.c} permite tres posibles configuraciones típicas:
\begin{enumerate}
\item Los sensores y actuadores del robot real pueden estar físicamente conectados al ordenador en el que se ejecuta \textit{jde.c}. Por ejemplo, con la base motora del pioneer conectada al puerto serie del ordenador portátil, y el par de cámaras a su bus firewire. La plataforma incorpora los \textit{drivers} oportunos para resolver el acceso local a esos dispositivos.
\item Los sensores y actuadores pueden estar simulados y \textit{jde.c} se conecta al simulador.
\item \textit{jde.c} se conecta a los \textit{servidores de red} que a su vez están finalmente enlazados con los dispositivos hardware locales o con un simulador. La ventaja de usar estos servidores es que los dispositivos y la aplicación robótica no tienen que estar necesariamente en la misma máquina.
\end{enumerate}

Como veremos en la sección \ref{sec:variables}, la misma variable se puede conectar a diferentes dispositivos del mismo tipo. Por ejemplo, la misma variable para imágenes se puede conectar a una cámara firewire, a una webcam USB o a una cámara analógica enchufada a una tarjeta digitalizadora. La plataforma incorpora los \textit{drivers} necesarios para cada caso y en todos los casos las imágenes llegan a la aplicación a través de la misma variable exactamente. De esta manera se uniformiza el acceso y la plataforma amortigua parte de la heterogeneidad del hardware, que no afecta tanto al código de las aplicaciones.

%\vspace{0.5cm}
\subsubsection{La aplicación robótica es una colección de esquemas}
%modelo de esquemas concurrentes
En cuanto a la arquitectura software concreta, dentro de \textit{jde.c} las aplicaciones robóticas se conciben y organizan como un conjunto de esquemas concurrentes. Un \textit{esquema} no es más que una hebra con cierto objetivo, que se ejecuta iterativamente a un ritmo controlado. Para aplicaciones reactivas sencillas, probablemente con un único esquema que tiene muchas iteraciones por segundo resulte suficiente. 

Para aplicaciones algo más complejas \textit{jde.c} propone dividir la funcionalidad en esquemas perceptivos y esquemas de actuación concurrentes, todos al mismo nivel. Los esquemas perceptivos tratan los datos sensoriales y elaboran nueva información, que se ofrece a los demás esquemas como nuevas variables compartidas. Los esquemas de actuación recogen la información sensorial o de otros esquemas perceptivos y toman decisiones de actuación.

Para aplicaciones aún más complicadas \textit{jde.c} propone organizar la colección de esquemas en una jerarquía de varios niveles, donde unos activan a otros. De hecho los esquemas se inicializan, se modulan durante su ejecución, se pueden detener y relanzar a voluntad. Aqui la novedad de esta plataforma es que no se encapsula la funcionalidad en un conjunto de funciones que se invocan, sino en un conjunto de esquemas concurrentes que se activan y modulan entre sí. Esta división software tiene su sustrato teórico en la arquitectura cognitiva JDE \cite{canas03} para generar comportamiento autónomo en robots.
 
\subsection{Contexto software de jde.c}

%nicho al que se dedica: pc, lenguaje C y linux
Más que vocación de universalidad, el objetivo de \textit{jde.c} es ayudar en la programación de un modelo concreto, el robot Pioneer enriquecido con cámaras, tanto real (figura \ref{fig:dospioneers}) como simulado. Alrededor de este objetivo fundamental hay unas decisiones de diseño que fijan el contexto software en el que \textit{jde.c} funciona. 

\begin{figure}[htb]
\begin{center}
\includegraphics[width=6.5cm]{figs/pioneer-stereo}
\end{center}
\caption{Robot Pioneer con cámaras}
\label{fig:dospioneers}
\end{figure}

%PC
En primer lugar, \textit{jde.c} está orientada a robots con ordenadores personales (portátiles, de sobremesa, empotrados...) como procesadores principales. Esta decisión coincide con la proliferación de los PCs en los robots de centros de investigación, que se explica por su precio asequible, su crecimiento continuo en la velocidad de cálculo y por las abundantes herramientas de programación disponibles para ellos.

%linux
En segundo lugar, \textit{jde.c} funciona sobre el sistema operativo \texttt{GNU/Linux}. Además de ser el más usado por los autores, tiene detrás una comunidad muy activa y amplia de desarrolladores, lo cual garantiza en la práctica la incorporación del soporte de los nuevos dispositivos hardware que van ofreciendo los avances tecnológicos. Otras ventajas son que es software libre y que la actualización del sistema es muy sencilla. Además, ofrece un amplio abanico de aplicaciones y herramientas de programación. Aunque no ofrece tiempo real \textit{duro} resulta suficientemente ágil para nuestras aplicaciones robóticas.

%lenguaje C
En tercer lugar, el lenguaje C es el elegido para desarrollar \textit{jde.c} y las aplicaciones sobre ella. Este lenguaje supone un buen compromiso entre potencia expresiva y rapidez. Como lenguaje compilado su eficiencia temporal es superior a otros lenguajes interpretados. Además gran parte del software proporcionado por los fabricantes de robots y por muchos grupos de investigación está escrito en este lenguaje. La reutilización o integración de software es más factible en este lenguaje común. Recientemente se puede observar en la comunidad robótica un crecimiento de los desarrollos en C++. Una ventaja es que la portabilidad desde C a C++ es relativamente sencilla.

%multitarea, interfaz gráfico y comunicaciones
Finalmente hemos elegido varias bibliotecas sobre las que apoyar el código de \textit{jde.c}, con el criterio de que fueran suficientes, estables y ampliamente usadas. Para materializar las hebras de las aplicaciones robóticas hemos elegido la biblioteca \textit{Pthreads}. Para programar las interfaces gráficas, la biblioteca \texttt{Xforms} \cite{zhao00}, que se monta encima de Xlib, dentro del sistema de ventanas \texttt{X-Window}. Y para las comunicaciones entre procesos ejecutando en máquinas diferentes hemos elegido la biblioteca de \textit{sockets} de GNU/Linux.


\section{Hardware y software soportados}

El entorno \textit{jde.c} está orientado a facilitar la programación de los robot Pioneer que tenemos en la Universidad Rey Juan Carlos. La plataforma se puede conectar: (a) localmente al robot real, (b) al simulador o (c) remotamente a cualquiera de ellos vía los servidores de red. Estas tres son las configuraciones típicas, siempre en torno a los mismos sensores y actuadores, y en todas ellas \textit{jde.c} mantiene el mismo interfaz de programación, que detallaremos en la sección \ref{sec:variables}. En esta sección describiremos las características de esos sensores y actuadores soportados por la plataforma. 

\subsection{El robot real}
\label{sec:pioneer}
%hardware

En cuanto al hardware, el robot de referencia es el de la figura \ref{fig:dospioneers}. El procesador principal es un ordenador portátil al que se conectan todos los dispositivos: una base Pioneer 2DXE\cite{activmedia03}, un cuello mecánico, un par stereo de cámaras firewire y un sensor láser. En la figura \ref{fig:bloqueshw} se aprecia el diagrama de bloques. El ordenador portátil es actualmente un procesador Pentium-III a 600 MHz, y en él se ejecutan la mayor parte de los programas para generar comportamiento. Una ventaja de este montaje es que se puede renovar fácilmente el ordenador a medida que se queda obsoleto. Al ser un elemento estándard se puede reemplazar por otro más moderno y rápido a un precio asequible.
Adicionalmente el portátil está conectado a la red exterior a través de un enlace inalámbrico, con una tarjeta de red 802.11, que le proporciona un ancho de banda de 11 MBps en sus comunicaciones hacia el exterior. De este modo el programa de control puede ejecutarse a bordo del robot o en cualquier otro computador. Además de ofrecer funcionamiento autónomo esta disposición permite la visualización e interacción en tiempo real con máquinas fijas.
 
\begin{figure}
\begin{center}
\includegraphics[height=4cm]{figs/pioneer-struct}
\end{center}
\caption{Diagrama de bloques del hardware del robot real}
\label{fig:bloqueshw}
\end{figure}

\subsubsection{Base Pioneer}

Esta base la comercializa la empresa norteamericana ActivMedia Robotics \footnote{http://www.mobilerobots.com} y tiene una comunidad de usuarios bastante extensa, lo que facilita la resolución de dudas y problemas. En el apartado sensorial la base consta de una corona de sensores de contacto en su parte inferior, otra de sensores de ultrasonido y un par de encoders asociados a sendas ruedas motrices. Los actuadores principales de los que dispone esta plataforma son dos motores de continua, cada uno asociado a una rueda, controlados por PWM. Con ellos se dota al robot de un movimiento de tracción diferencial (tipo tanque). Con unas velocidades máximas de 1.8 $mm/seg$ y de 360 $grados/seg$. Es capaz de cargar 23 Kg de peso.

%procesadores
La base dispone de un microprocesador Siemens 88C166 situado en la base motora, ejecutando instrucciones a 20 MHz. En este microcontrolador funciona un sistema operativo especial llamado P2OS, que se encarga de recoger las medidas de los sensores de ultrasonido, de los encoders y de materializar los comandos motores que le llegan. El microcontrolador se conecta al ordenador externo a través de un puerto serie, con el que establece un diálogo.

%tactiles
Los sensores más sencillos que permiten detectar obstáculos son los de contacto. El Pioneer en concreto tiene 5 sensores delante y 5 detrás, que le permiten discernir el punto de impacto. Éstos entregan lecturas binarias: choque, no-choque.

%sonars
A unos 15 cm del suelo hay una corona de sensores de ultrasonido, con 8 sensores en la parte delantera y otros 8 sensores en la parte trasera. Los sensores de ultrasonido miden distancia a los obstáculos cercanos. Emiten una onda ultrasónica que rebota en los obstáculos que pueda haber delante del sensor. Midiendo el tiempo que tarda en llegar el eco estiman la distancia hasta el obstáculo. Estos sensores tienen ciertas incertidumbres asociadas. La energía ultrasónica se propaga con un frente de onda circular que se expande y conforma un patrón de energía de forma lobular (figura \ref{fig:sensorsonar}). En el interior del lóbulo hay espacio vacío, porque en caso contrario el eco hubiera retornado antes. En algún punto del arco frontal hay un obstáculo que ha provocado el retorno de cierta energía ultrasónica. 
%En la parte derecha de la figura \ref{fig:sensorsonar} se muestra el modelo medido experimentalmente. Las distancias se expresan en milimetros y como se observa, tiene una forma cónica y un alcance máximo de 3 metros. Cada segundo se obtienen 3 lecturas completas de toda la corona.

\begin{figure}
\begin{center}
\begin{tabular}{c@{\hspace*{1.cm}}c}
\includegraphics[width=8cm]{figs/modelosonar} &
\includegraphics[width=7cm]{figs/sonarpioneerexp} \\
\end{tabular}
\end{center}
\caption{Interpretación de la lectura sonar (izquierda) y alcance experimental (derecha)}
\label{fig:sensorsonar}
\end{figure}

\begin{figure}
\begin{center}
\begin{tabular}{c@{\hspace*{1.cm}}c}
\includegraphics[width=4cm]{figs/sonarsensor} &
\includegraphics[width=4cm]{figs/sonarpioneer} \\
\end{tabular}
\end{center}
\caption{Sensor de ultrasonidos y corona en la base Pioneer}
\label{fig:sonarnumbers}
\end{figure}

%encoders
Asociado a cada una de las ruedas, la base tiene un sensor de odometría. Estos odómetros cuentan 500 pulsos por cada giro completo de la rueda, lo que se traduce en 66 $ticks/mm$. Su uso más importante es para estimar su posición, y con ellos se puede estimar además la velocidad real a la que se mueve el robot. Su principal problema es que acumulan error debido al deslizamiento de las ruedas y a desalineamientos. Estos sensores proporcionan lo que han girado las ruedas izquierda y derecha del robot en cierto intervalo. Desde esas lecturas y conocidas las coordenadas de su posición anterior $(x(t-1),y(t-1),\theta (t-1))$ es fácil calcular la nueva posición empleando un razonamiento incremental. Estos cálculos los lleva a cabo en sistema operativo del microcontrolador, que realiza la conversión a coordenadas absolutas X, Y, $\theta$.

%drivers
El fabricante proporciona la biblioteca ARIA para crear programas en el ordenador personal que se comuniquen con este microprocesador.

\subsubsection{Láser}
%laser  
Hemos incorporado al robot un sensor láser, de la casa SICK, que mide las distancia a los obstáculos. El modelo LMS-200\cite{sick02,sick03} proporciona 10 barridos por segundo, con una precisión de 1 grado y $2cm$. Tal y como muestra la figura \ref{fig:variable_laser}, el láser ofrece perfiles del entorno mucho más nítidos y fiables que los sónares. Su principal inconveniente es el precio, que lo hace prohibitivo para robots comerciales. Se alimenta con una tensión continua de 24 Voltios, que se extraen con una placa elevadora de tensión desde los 12 Voltios internos del robot. 

\begin{figure}
\begin{center}
\begin{tabular}{c@{\hspace*{2.cm}}c} 
\includegraphics[width=6cm]{figs/sensorlaser} &
\includegraphics[width=6cm]{figs/laserpioneer} 
\end{tabular}
\end{center}  
\caption{Sensor laser}  
\label{fig:sensorlaser}  
\end{figure}  

El sensor entrega sus lecturas a través de un puerto serie convencional siguiendo el protocolo del fabricante descrito en \cite{sick03}. En general este sensor es muy fiable y preciso, aunque no detecta bien los cristales transparentes.
 
%driver
Se ha reutilizado un \textit{driver} de CARMEN, que configura adecuadamente al dispositivo láser en cuanto a su resolución angular, modo de operación, velocidad de emisión y utiliza el puerto serie a 38400 baudios. Este \textit{driver} entiende el formato de mensajes en el puerto serie que establece el fabricante del sensor, y refresca las variables en las que vuelca las medidas del láser. Además ofrece una interfaz de funciones en C para iniciar al dispositivo (\texttt{sick\_start\_laser}), lanzar o detener la captura (\texttt{sick\_stop\_continuous\_mode},\texttt{sick\_start\_continuous\_mode}) y muestrear de modo no bloqueante si hay nuevos mensajes del sensor en el puerto serie.

\subsubsection{Cámaras}

En cuanto a la visión, la plataforma \textit{jde.c} incluye soporte para \textit{dos} cámaras simultáneamente (par stereo), y para varios tipos de ellas. Básicamente las cámaras proporcionan información de color y de bordes, y si se calibran correctamente puede extraerse de las imágenes información espacial, geométrica. 

%cámara usb
\textit{jde.c} soporta cámaras de videoconferencia USB (webcams). Estas cámaras son digitales (CCD) por lo que no requiere de tarjetas digitalizadoras, y se conectan al ordenador a través del puerto USB. En particular usamos el modelo PCVC-740K de Philips (figura \ref{fig:sensorvision}), que tiene un soporte bastante bueno en Linux\footnote{\texttt{http://www.smcc.demon.nl/webcam/}}. Entrega imágenes de 640x480 pixels a un ritmo de 15 fps, o imágenes de 320x240 a 30 fps (utilizando un driver con compresión en ambos casos). Apenas tiene distorsión radial y su precio es muy bajo (alrdedor de 60 euros).
%drivers
Las imágenes de esta cámara llegan a la aplicación (ya sea localmente o a través de servidor de red) usando \textit{video4linux}. Afortunadamente \textit{video4linux} también incluye el soporte para cámaras analógicas enganchadas a una tarjeta digitalizadora, por lo que se pueden usar en \textit{jde.c} sin problemas.

\begin{figure}
\begin{center}
\begin{tabular}{c@{\hspace*{2.cm}}c} 
\includegraphics[width=6cm]{figs/camarausb} &
\includegraphics[width=6cm]{figs/parstereo} 
\end{tabular}
\end{center}  
\caption{Cámara USB y cámaras Apple-isight}  
\label{fig:sensorvision}  
\end{figure}  

%cámara firewire
En la configuración actual, el robot tiene un par stereo de cámaras firewire, modelo Isight de Apple. Estas cámaras tienen una óptica muy buena y son razonablemente baratas (unos 150 euros). Además incorporan autofocus y balance automático de blancos. Ambas se conectan al bus firewire del ordenador portátil empleando el mismo \textit{hub} (figura \ref{fig:sensorvision}). La velocidad de las cámaras y la capacidad del \textit{hub} permiten entregar al ordenador dos flujos de 30 imágenes por segundo, a 320x240. Una ventaja del bus firewire (también llamado ieee1394) frente al USB tradicional es que los datos de las imágenes llegan por DMA a la memoria, liberando de esa tarea a la CPU del ordenador, que queda más desahogado para el resto de tareas.
%drivers
El soporte software para estas cámaras reside en dos bibliotecas, una básica (\texttt{libraw1394}) para manejo del bus firewire (ya sean cámaras, discos duros u otros dispositivos raros los que se conectan) y otra especializada en cámaras digitales (\texttt{libdc1394\_control}). Ambas están escritas en lenguaje C. Hemos probado con éxito otros modelos de cámara firewire como las Videre DCAM-L.

\subsubsection{Cuello mecánico}

Otro dispositivo del robot real es el cuello mecánico, que usando dos motores permite mover a voluntad las cámaras horizontal y verticalmente. El modelo usado es la unidad pantilt PTU-46-17.5 \cite{directed03} de la empresa Directed Perception. 
%drivers
El cuello se conecta al ordenador a través de un puerto serie. Usando un protocolo especificado por el fabricante se le puede ordenar que vaya a determinada posición absoluta, a determinada posición relativa respecto de la posición actual, que se mueva a cierta velocidad, etc.. El movimiento de los dos motores, el que gira en horizontal y el que lo hace en vertical, se lleva a cabo simultáneamente, con sendos controladores PWM independientes ejecutando en paralelo. Además, los motores del cuello tienen \textit{encoders} asociados, de manera que el dispositivo puede comunicar continuamente al ordenador su posición actual.

\begin{figure}
\begin{center}
\includegraphics[width=5cm]{figs/ptu_lrg}
\end{center}
\caption{Unidad pantilt, cuello mecánico}
\label{fig:pantilt}
\end{figure}

\subsection{Simuladores}

Una herramienta muy útil en la programación de robots son los simuladores. Estos ofrecen un entorno virtual en el que emulan las observaciones de los sensores y los efectos de las órdenes a los actuadores. Sirven para evaluación, depuración y ajuste de la aplicación robótica antes de ser llevada al robot físico. Otra ventaja en docencia es que todos los alumnos, aunque sean muchos, pueden hacer sus prácticas en su casa, sin necesidad de que se lleven al robot real. 

\textit{jde.c} incorpora los simuladores por debajo del interfaz de variables perceptivas y de actuación, de manera totalmente transparente para la aplicación. Más que hacernos un simulador hemos preferido utilizar algunos de los existentes en la comunidad robótica.

\subsubsection{El simulador SRISim}

La distribución de ARIA incluye el simulador SRISim (figura \ref{fig:SRISim}) capaz de manejar mundos bidimensionales estáticos con en único robot moviéndose por él. Es capaz de simular odometría, motores y sónares. 
%simula laser?
Se arranca con el comando \texttt{SRISim}:

\begin{verbatim}
SRIsim [-w world_file] [-r robot_type] [-t port_type] [-p port_name]
  [-timeout .1sec increments] [-s shrink_factor] [-g grow_factor]
\end{verbatim}

\begin{figure}[ht]
\begin{center}
\resizebox{.5\textwidth}{!}{\includegraphics{figs/srisim}}
\end{center}
\caption{SRISim con el mapa del Departamental I}
\label{fig:SRISim}
\end{figure}

Los parámetros por defecto son robot P2DX con sonar frontales y traseros, conexión TCP en el puerto 8101 y sin {\em timeout} de desconexión (tiempo sin recibir comandos). Los PATHs en los que busca los ficheros de definición del mundo y del robot son relativos a la instalación de ARIA.

\subsubsection{El simulador Stage}

Uno de los simuladores más potentes es Stage, que se encuadra en el proyecto de software libre \htlink{Player/Stage/Gazebo}{http://playerstage.sourceforge.net/}. Este simulador tiene detrás una comunidad muy activa de desarrolladores y ha extendido mucho su uso en los últimos años, convirtiéndose en un estandard de facto.

\begin{figure}[ht]
\begin{center}
\resizebox{.5\textwidth}{!}{\includegraphics{figs/stage}}
\end{center}
\caption{Simulador Stage}
\label{fig:stage}
\end{figure}

Stage simula muchos modelos de robots, entre ellos los de base Pioneer, y muchos dispositivos sensoriales y de actuación. En particular, simula los motores de la base, la odometria, los sónares y láser de nuestro robot de referencia. No simula las cámaras ni el cuello mecánico. Stage está orientado a mundos bidimensionales, donde hay objetos estáticos, otros robots o incluso cosas que se pueden empujar. La capacidad de simular varios robots en el mismo mundo permite poner obstáculos dinámicos y probar cómo un robot se comporta frente a ellos.

\subsection{Servidores de red: otos y óculo}

%acceso remoto
Para poder tener el robot en una máquina y la aplicación de control en otra creamos los servidores de red \textit{otos} y \textit{óculo}, que ofrecen acceso remoto al robot, tanto real como simulado. Cada servidor encapsula ciertos sensores y actuadores que hay en su máquina y ofrece su funcionalidad al resto de los programas a través de una \textit{interfaz de mensajes}. \textit{Jde.c} actúa como cliente, establece una conexión \texttt{tcp} con el/los servidores, solicita medidas sensoriales y envía comandos intercambiando mensajes. El servidor \texttt{otos} incluye el acceso a los motores de la base, los sensores de proximidad (como los sónares o el láser) y los sensores de odometría. El servidor \texttt{óculo} se encarga de los sensores de imagen y del movimiento del cuello.

%La plataforma crea los buffers de recepción oportunos, así como dedicar cierta parte del tiempo de cómputo del programa a las comunicaciones (con muestreo periódico, activado por eventos, etc.) para recoger de los servidores las observaciones en los sensores del robot y enviar a los motores las órdenes de movimiento, a través de los servidores. 

%ventaja: procesamiento distribuido
%desventajas: retardo y desincronizacion
Ambos servidores admiten varios clientes simultáneamente. Esta arquitectura facilita el procesamiento distribuido y permite poner la aplicación en la máquina más rápida. No hay problema en que servidor y cliente se ejecuten en la misma máquina, la interfaz de mensajes es transparente a la ubicación de unos y otros. Este planteamiento conlleva un cierto aumento de los retardos entre que se lee el dato sensorial y éste llega, atravesando los servidores y la red, al programa donde realmente se procesa. Otro inconveniente es cierta desincronización de las medidas. En un único procesador al que se atan los sensores todas esas lecturas están datadas muy precisamente por el reloj del ordenador local. Al introducir los servidores y los retardos variables de la red el tiempo con el que se datan las lecturas en el programa que las recibe puede no ser tan preciso.

%%protocolo
%Entre los servidores y los clientes se establece un diálogo, regulado por un protocolo que está pensado para el envío continuo (streaming). En él hemos establecido tres patrones de interacción: (1) la suscripción a sensores cortos como el láser, la odometría o los ultrasonidos, (2) el envío bajo demanda de imágenes y (3) las órdenes de movimiento.
%formato de linea: sintaxis
%Hemos fijado un \textit{formato de línea} en el cual se intercambian los mensajes del protocolo. Todos los mensajes empiezan por un número entero que indica el tipo de mensaje, pueden incluir varios argumentos y acaban en un retorno de carro. El contenido de los mensajes siempre se envía como texto ASCII.

\subsubsection{Servidor otos}

El servidor \texttt{otos} reúne los servicios de los sensores de proximidad como sónares y láser. También permite enviar comandos de movimiento a los motores de base y entrega los datos de odometría que generan sus encoders, tanto la posición como la velocidad estimada a partir de ellos.

Para todos esos sensores ofrece un \textit{servicio de suscripción directa}, que consiste en que el cliente, una vez conectado, se suscribe a un determinado sensor y el servidor le entrega datos de ese sensor cada vez que haya medidas nuevas. Los clientes pueden suscribirse exclusivamente a los sensores de su interés por separado, discrecionalmente, y desuscribirse a voluntad en cualquier momento. El servidor tiene la iniciativa y envía una lectura sólo cuando hay un nuevo dato. En este sentido hay garantía de que al cliente le llegan todas las lecturas y cada una de ellas sólo una vez.

%actuadores
Respecto a los actuadores, el protocolo ofrece un \textit{servicio de acciones}, que consiste en el envío de una órden, sin esperar confirmación de que se ha ejecutado. En concreto permite ordenar un control en velocidad de la tracción y del giro respectivamente. Tienen una semántica no acumulativa en el tiempo.

\begin{table}
\begin{center}
\small
\begin{tabular}{|p{10cm}|}
\hline
socket 3000\\
pioneer\_device stage\\
laser\_device stage\\
robot\_model ./pioneer.aria\\
\#this is a comment line\\
stage localhost 6665\\
\hline
\end{tabular}
\end{center}
\normalsize
\caption{Fichero ejemplo de configuración para el servidor \texttt{otos}}
\label{tabla:otos.conf}
\end{table}

%otos se conecta al simulador
El servidor \texttt{otos} puede conectarse indistintamente al simulador o al robot real (figura \ref{fig:jdeglobal}). Esto se especifica en un fichero de configuracion como el de la tabla \ref{tabla:otos.conf}, en el cual se indica el puerto serie para hablar con la base Pioneer, el puerto serie para hablar con el sensor láser, o el simulador al que se quiere conectar. También se especifica el puerto socket en el que otos atenderá a sus clientes. \texttt{otos otos.conf}.

\subsubsection{Servidor óculo}

%imágenes
El servidor \texttt{óculo} aúna las funciones asociadas al cuello mecánico y a las cámaras. Con ello permite a los clientes mover la unidad pantilt a voluntad especificándole ángulos objetivo y pone a disposición de los clientes el flujo de imágenes obtenidas con las cámaras. Puede transmitir varios formatos de imagen: en niveles de gris, imágenes logpolar e imágenes RGB.

Debido al ancho de banda necesario para transmitir imágenes éstas se ofrecen a los clientes a través de un servicio \textit{bajo demanda}: cada vez que el cliente necesita una imagen la solicita con un mensaje explícito y el servidor le responde con dos mensajes, uno de cabecera donde se especifica el tamaño de la imagen subsiguiente, y otro especial donde va la imagen en sí misma. Una ventaja es que permite desacoplar el ritmo de captura del ritmo al que es capaz de procesar imágenes el cliente. Por ejemplo, si un cliente ejecuta algoritmos de visión computacional y es capaz de digerir 5 imágenes por segundo, no tiene sentido saturarle con los 25 fps que es capaz de capturar la cámara. El servicio bajo demanda permite que al cliente le lleguen imágenes al ritmo que es capaz de procesar, ni más ni menos. 

%pantilt
La posición de la unidad pantilt es una información sensorial, y se trata con un servicio de suscripción directa. Las órdenes de movimiento a la pantilt son controles en posición angular, tanto horizontal como vertical, sin sentido acumulativo, ya que la última orden que llega para cada dimensión es la que se obedece. De momento no se han incorporado a \texttt{óculo} actuaciones como los niveles de enfoque, o activar/desactivar el autoiris.


\begin{table}
\begin{center}
\small
\begin{tabular}{|p{10cm}|}
\hline
socket 3001\\
video 0 file:atardecer.ppm\\
video 1 firewire:0\\
\#this is a comment line\\
\#video 0 video4linux:/dev/video0\\
\hline
\end{tabular}
\end{center}
\normalsize
\caption{Fichero ejemplo de configuración para el servidor \texttt{óculo}}
\label{tabla:oculo.conf}
\end{table}


%fichero configuracion
El servidor \textit{óculo} admite un fichero de configuracion en el que se especifica en qué puerto escuchar a los clientes, qué puerto serie tiene conectada la unidad pantilt y en qué dispositivo/s está/n la/s cámara/s. \texttt{oculo oculo.conf}. El número de puerto ha de ser mayor que 1024, porque esos ya están reservados para el sistema. En la tabla \ref{tabla:oculo.conf} se muestra un ejemplo.

\section{Variables perceptivas y de actuación}
\label{sec:variables}

%variables, no hay que enviar mensajes
Una vez que hemos descrito los sensores y actuadores del robot de referencia \ref{sec:pioneer}, en el entorno \textit{jde.c} se ponen a disposición de los programas de aplicación en forma de variables compartidas (perceptivas o de actuación respectivamente). En esta sección vamos a describir en qué \textit{variables perceptivas} concretas se ofrecen las medidas del láser, los sensores de ultrasonido, los datos de odometría, las imágenes de la cámara, etc., su interpretación física y unidades. También detallaremos las \textit{variables de actuación} que se utilizan para comandar órdenes a los motores de la base o del cuello mecánico.

Bien sea utilizando los drivers locales, el diálogo con el simulador o la comunicación remota con los servidores de red, la plataforma mantiene las variables sensoriales continuamente refrescadas a su último valor, y periódicamente (cada 100 ms) envía los comandos contenidos en las variables de actuación a los actuadores. La aplicación robótica, en esencia, leerá asíncronamente las variables perceptivas cuando lo necesite y escribirá asíncronamente los comandos motores oportunos en las variables de actuación. De esta manera el control reside en la aplicación robótica y la plataforma se convierte en un mero intermediario que pone a su disposición sensores y actuadores.

%Cierta latencia, tanto en las observaciones como en las actuaciones. Variables compartidas: protección con semáforos para evitar condiciones de carrera.

\subsection{Sensores odómetricos y sistemas de referencia}

%robot0,robot1,robot2
Los sensores odométricos miden la posición y orientación del robot en el mundo bidimensional. \texttt{robot[0]} es la $X_{robot}$ de la figura \ref{fig:odometry}, \texttt{robot[1]} la $Y_{robot}$, ambas en milímetros. Por su parte \texttt{robot[2]} contiene la orientación del robot en el mundo, $\theta_{robot}$ de la figura, expresada en radianes. Por su parte \texttt{robot[3]} y \texttt{robot[4]} son variables auxiliares que contienen $cos(\theta_{robot})$ y $sen(\theta_{robot})$, lo cual resulta muy útil para realizar cambios de coordenadas de manera eficiente. Estas coordenadas del sistema odométrico están referenciadas a un sistema absoluto externo, fijo, normalmente coincidente con la posición y orientación del robot cuando se enciende. A medida que el robot se mueve por el mundo, sus coordenadas varían. En el robot real la posición se actualiza 10 veces por segundo.

\begin{figure}
\begin{center}
\includegraphics[width=9cm]{figs/variable_odometria}
\end{center}
\caption{El robot en el mundo, posición obtenida desde odómetros}
\label{fig:odometry}
\end{figure}

%ruido
Esta estimación de posición la realiza la propia base Pioneer basándose en los cuentavueltas (\textit{encoders}) asociados a sus dos ruedas motrices. Por ejemplo, si los dos cuentavueltas han girado lo mismo en cierto lapsus pequeño de tiempo es que el robot se movió en línea recta una distancia que depende del radio de las ruedas. Si la rueda de la derecha giró más es que el robot rotó hacia su izquierda. Una característica de esta estimación es que acumula ruido, es decir, después de que avance unos metros y gire unos cuantos ángulos la estimación se degrada, se la aleja de la posición absoluta real. Cuanto más se mueve, más error acumula. Si se necesita la posición exacta, esta estimación se puede corregir empleando técnicas de localización específicas.

%%espacio odometrico: expresar todo en absolutas pero usarlo en relativo. De este modo no se acumula mucho error y la actualización de posiciones es menos costosa que si mantuviera todo en relativas.

%varios sistemas de referencia y cambios de coordenadas
A la hora de programar robots se suelen usar varios sistema de referencia para expresar la posición y orientación de las cosas. Por un lado está el \textit{sistema de referencia absoluto}, en el cual se puede expresar la posición del robot y la de cualquier obstáculo, destino de navegación, etc.. 

Un segundo sistema interesante es el \textit{sistema de referencia solidario con el propio robot}. En el caso de \textit{jde.c} hemos convenido usar como eje X de este sistema el que señala al frente del robot, como eje Y el que señala hacia su izquierda y como origen de este sistema un punto situado en el mismo centro geométrico del robot. Este sistema es útil para expresar las coordenadas relativas de obstáculos, puntos de navegación, objetos, etc. respecto del robot. Por ejemplo, en la figura \ref{fig:srefrobot} si el robot se mueve, aunque el punto P permanezca quieto en el espacio, sus coordenadas relativas sí varían. Sabiendo la posición (desplazamiento en X y en Y) y orientación (1 ángulo) del robot en el mundo es sencillo pasar las coordenadas relativas a absolutas o viceversa. Para ello basta usar un cambio de coordenas que incorpora el giro y la traslación de un sistema respecto del otro.

Un tercer sistema de referencia útil es el solidario a algún sensor. Por ejemplo el sistema de referencia solidario con el sensor láser o solidario con las cámaras. Conociendo la posición y orientación del sensor respecto del centro del robot se pueden cambiar las coordenadas a coordenadas relativas al robot y de ahí a absolutas.

\begin{figure}
\begin{center}
\includegraphics[width=6cm]{figs/srefrobot}
\end{center}
\caption{Coordenadas de un punto respecto del sistema de referencia solidario con el robot}
\label{fig:srefrobot}
\end{figure}

Para la mayoría de las aplicaciones robóticas resulta suficiente un sistema de referencia bidimensional, que asume un mundo plano y liso. Si se van a manejar cámaras pueden ser útiles sistemas de referencia tridimensionales, que ya incluyen la coordenada Z. En este caso las traslaciones entre sistemas de referencia incluyen 3 desplazamientos (en X, en Y y en Z) y tres ángulos para especificar las orientaciones relativas.

\subsection{Sensor láser}

Las medidas del sensor láser se almacenan en el array de 180 enteros \texttt{int laser[180]}. En ese array se tiene la distancia en milímetros para cada uno de los ángulos de barrido del sensor. Según muestra la figura \ref{fig:variable_laser}, el primer valor \texttt{laser[0]} corresponde a la medida más a la derecha del sensor, con su frente hacia delante.

Tal y como está configurado, el láser ofrece 10 medidas por segundo, con una precisión angular de 1 grado. El rango angular es de 180 grados. En distancia el alcance máximo es de 8 metros. Si una determinada lectura entrega 8 metros es que en ese ángulo no se detectó obstáculo ninguno. Es un sensor muy fiable por lo que su simulación se corresponde con bastante fiabilidad a un funcionamiento real.

\begin{figure}
\begin{center}
\includegraphics[width=10cm]{figs/variable_laser}
\end{center}
\caption{Medidas del sensor láser en la variable \texttt{laser[i]}}
\label{fig:variable_laser}
\end{figure}

En la configuración más usada, el láser está situado paralelo al suelo, a una altura de unos 30 cm y situado mirando al frente del robot. Su posición respecto al sistema de referencia solidario con el robot se puede variar mecánicamente y para que el software lo tenga en cuenta hay que retocar algunas constantes.

\subsection{Sensores de ultrasonido}

Las medidas de la corona de ultrasonidos se almacenan en el array de 16 enteros \texttt{float us[16]}. En ese array se tiene la distancia en milímetros medida por cada uno de los sensores. El primer valor \texttt{us[0]} corresponde a la medida más a la izquierda del robot, según muestra la figura \ref{fig:variable_us}.

La corona entrega unas tres lecturas completas por cada segundo, y el alcance máximo es de 3 metros. Lecturas superiores a ese valor suelen reflejar medidas erróneas por reflexiones especulares o pérdida de ecos. Suele ser un sensor bastante ruidoso, que falla en los rincones o cuando los ángulos de incidencia entre sensor y obstáculo se alejan de la perpendicularidad.

\begin{figure}
\begin{center}
\includegraphics[width=9cm]{figs/variable_us}
\end{center}
\caption{Medidas de los sónares en la variable \texttt{us[i]}}
\label{fig:variable_us}
\end{figure}

Las posiciones y orientaciones de los sensores respecto del sistema de referencia del robot son fijas. Se suministran al software en la variable \texttt{coord[]}, que se rellena con constantes al iniciar la plataforma \textit{jde.c}. Es necesario almacenarlas para poder cambiar de sistema de referencia a voluntad. Gracias a ello un punto detectado por el sensor de ultrasonidos lo podemos expresar en el sistema de referencia del sensor, en el solidario con el robot o en el del mundo. Si \texttt{us[4]} vale 450 en un instante, se suele considerar que en la dirección apuntada por ese sensor hay espacio vacío hasta los 450 mm del robot, donde hay un obstáculo. Para una interpretación geométrica más fina se puede usar el modelo sensorial de la figura \ref{fig:sensorsonar}.

%\subsection{Sensores de contacto}
%\begin{figure}
%\begin{center}
%\includegraphics[width=4cm]{figs/sonarnumbers}
%\end{center}
%\caption{Numeración y posición de los sensores de contacto}
%\label{fig:bumpernumbers}
%\end{figure}

\subsection{Imágenes}

Las imágenes son las lecturas de las cámaras, y en \textit{jde.c} se soportan 2 cámaras simultaneamente.  En \textit{jde.c} se decidió normalizar el tamaño de las imágenes a 320x240 píxeles, que es un tamaño estandard, y su formato a RGB. La imagen en color obtenida por una cámara se almacena y refresca en el array \texttt{char colorA[3*320*240]}, y la otra en el array \texttt{char colorB[3*320*240]}. Dentro de esos arrays, con el índice creciente se va recorriendo la imagen de arriba a abajo y de derecha a izquierda. Se dedican 3 bytes por cada pixel, uno para la componente roja R, otro para la verde G, y otro para la azul B. 

\begin{figure}[htb]
\begin{center}
\begin{tabular}{c@{\hspace*{1.cm}}c}
\includegraphics[width=6.5cm]{figs/colorA} &
\includegraphics[width=6.5cm]{figs/colorB}\\
\end{tabular}
\end{center}
\caption{Imágenes del par stereo}
\label{fig:imagenes}
\end{figure}

Se puede trabajar con las dos cámaras simultáneamente o emplear sólo una de ellas.

Conceptualmente son otro sensor más, pero en cuestiones prácticas, el enorme caudal de datos que implican y la complejidad de su procesamiento conllevan un tratamiento especial. Si se quiere trabajar en otro espacio de color, como el HSI o con en niveles de gris, deben obtenerse las imágenes correspondientes transformando las originales \texttt{colorA} y \texttt{colorB}. Es típico en aplicaciones robóticas montar filtros de color, o filtros de borde encima de esas imágenes.

%La imagen en niveles de gris se almacena y refresca en la variable \texttt{mmbuf[]}, también de 320x240 pixels. Para cada pixel la intensidad toma un valor entre 0 y 255, es decir está discretizada a 8 bits.

\subsection{Motores de la base}

El principal actuador del robot son los motores que permiten desplazar y girar la base por el mundo. \textit{jde.c} ofrece un control en velocidad a través de las variables de actuación \texttt{float v} y \texttt{float w}, que son la velocidad lineal (en milímetros/seg) a la que se quiere que el robot avance y la velocidad de giro (en grados/seg) a la que se quiere que el robot rote sobre su eje.

Por convenio los valores positivos representan avances hacia delante y los negativos, retrocesos (mirando al frente). Los giros positivos representan giros en sentido horario y los negativos, giros en sentido antihorario. Ambos movimientos , traslación y giro, son simultáneos. Los valores máximos permitidos son $\pm$1000 mm/seg y $\pm$180 grados/seg, respectivamente. El software trunca valores por encima de estos límites.

Es un interfaz abstracto porque no ordena a los motores directamente y por lo tanto es extensible a robots con patas. En el caso del robot real, es el microprocesador de la base Pioneer quien traduce estas consignas a velocidades de cada motor.

\subsection{Motores del cuello mecánico}

El cuello mecánico se controla en posición, a través de dos variables de actuación \texttt{float latitude} y \texttt{float longitude}, en grados. Con \texttt{longitude} se le especifica el ángulo horizontal, contando con que el 0 está hacia el frente del cuello. El rango abarcable en horizontal va de -158 a 158 grados, que es casi una circunferencia completa salvo 40 grados de ángulo muerto no accesible. Con \texttt{latitude} se le ordena un ángulo en vertical, contando que el 0 está justo en la horizontal paralela al suelo. Los topes en vertical son 30 hacia arriba y -45 grados hacia el suelo. Si los valores permanecen constantes el cuello mecánico no se mueve de esa posición.

En el montaje usual el cuello mecánico está instalado encima del sensor laser, horizontalmente y mirando hacia el frente de manera que pueda girar hacia izquierda y derecha del robot. De todos los modos de operación que permite el aparato se ha elegido el de control en posición ``absoluta''.

\subsection{Posición del cuello mecánico}

La plataforma \textit{jde.c} periódicamente, cada 100 ms, pregunta al cuello cuál es su posición en ese instante. Estos valores los almacena en las variables perceptivas \texttt{float pan} y \texttt{float tilt}, que corresponden a la orientación actual \textit{medida} por los \textit{encoders} del dispositivo.

\begin{figure}
\begin{center}
\includegraphics[width=9cm]{figs/coordinatespt}
\end{center}
\caption{El cuello permite girar una cámara en horizontal y en vertical}
\label{fig:posicioncuello}
\end{figure}

Cuando se ordena un movimiento con las variables de actuación \texttt{latitude} y \texttt{longitude}, ese movimiento necesita cierto tiempo para llevarse a cabo, puesto que los motores no tienen aceleración infinita, tarda un tiempo en llegar. La trayectoria del cuello durante el movimiento se puede trazar viendo la evolución de las variables perceptivas \texttt{pan} y \texttt{tilt} que desembocarán justo en los valores comandados.

El uso clásico del cuello mecánico es orientar a voluntad una o dos cámaras que lleva encima. Por ejemplo en la figura \ref{fig:posicioncuello} hay una cámara montada encima del cuello mecánico, comandando diferentes posiciones se logra que la cámara barra toda escena.

%¿Velocidad de giro?

\section{Programando una aplicación robótica con esquemas}
\label{sec:esquemas}

%hebras de servicio
Como hemos descrito en la sección \ref{sec:variables}, \textit{jde.c} uniformiza el acceso a sensores y actuadores a través de variables compartidas, tanto si provienen del robot real, del robot simulado o de acceso remoto. Sobre este interfaz software 
%suelo software, interfaz de software, suelo estándard
se escribe el programa de la aplicación robótica. Para mantener este interfaz activo la plataforma ejecuta un conjunto de \textit{hebras de servicio}. Hay hebras de servicio que se encargan de recoger los datos de los sensores locales, de enviar los comandos a los actuadores locales, otras dialogan con el simulador y otras materializan la comunicación con los servidores de red. Cada ejecución de la plataforma se corresponde a una aplicación robótica, y para cada una de ellas se especifica en un fichero de configuración (\texttt{jde.conf}) qué variables perceptivas y de actuación se van a usar y de donde provienen (robot local, simulador, servidores de red), para que la plataforma ejecute las hebras de servicio oportunas.


\begin{table}
\begin{center}
\small
\begin{tabular}{|p{10cm}|}
\hline
sonars    otos localhost 3000\\
laser    otos localhost 3000\\
encoders   otos localhost 3000\\
motors  otos localhost 3000\\
\#schemas initialized:\\
guixforms\\
myschema\\
\hline
\end{tabular}
\end{center}
\normalsize
\caption{Fichero ejemplo de configuración para el jde, \texttt{jde.conf}}
\label{tabla:jde.conf}
\end{table}



%Modelo concurrente
%aplicación como una, varias o muchas hebras
Sobre este interfaz, \textit{jde.c} plantea la aplicación robótica como una o más hebras específicas que se ejecutan concurrentemente. La aplicación robótica puede constar de una única hebra en los casos sencillos, de varias en caso de comportamientos más elaborados o de un amplio conjunto dinámico de ellas en los comportamientos más complejos. Por lo tanto, \textit{jde.c} es un sistema \textit{multihilo} que tiene hebras de servicio y hebras específicas de la aplicación robótica ejecutándose en paralelo. En la implementación actual esas hebras se han materializado con la biblioteca \texttt{pthreads}. 

\subsection{¿Qué es un esquema?}

%esquema, flujo ejecución iterativo e interrumpible
Más que dejar libre el diseño de esas hebras de la aplicación, \textit{jde.c} ofrece la abstracción \textit{esquema} para estructurar su funcionamiento y que se puedan combinar de manera sencilla. Un \textit{esquema} es un flujo de ejecución que tiene un objetivo propio y funciona en iteraciones periódicas a un ritmo controlado. Los \textit{esquemas} se comunican entre sí a través de variables compartidas, se pueden detener y relanzar a voluntad. Encorsetar las hebras de la aplicación en los respectivos esquemas permite encapsular mejor la funcionalidad en unidades reutilizables para otras aplicaciones y simplificar la comunicación entre esas unidades. Para \textit{jde.c} el \textit{esquema} es la unidad básica de comportamiento y la aplicación robótica consta de un conjunto dinámico de \textit{esquemas} funcionando concurrentemente. 

\begin{table}
\begin{center}
\small
\begin{tabular}{|p{10cm}|}
\hline
/* variables de modulación */\\
int myschema\_cycle; /* tiempo de ciclo en ms */ \\
/* variables de entrada */\\
/* variables de salida */\\
\\
void myschema\_startup();\\
void myschema\_suspend();\\
void myschema\_resume(int *brothers, arbitration fn);\\
\\
void myschema\_thread();\\
void myschema\_iteration();\\
\hline
\end{tabular}
\end{center}
\normalsize
\caption{Interfaz de un esquema}
\label{tabla:interfazesquema}
\end{table}

%interfaz de esquema: startup, suspend y resume
Cada esquema tiene un nombre y cinco funciones asociadas, que tienen el nombre del esquema como prefijo. En la tabla \ref{tabla:interfazesquema} se muestran las de \texttt{myschema} a modo de ejemplo. La función \texttt{startup} se usa para dar de alta al esquema en el sistema e inicializarlo. La función \texttt{resume} para arrancar la ejecución iterativa o reactivarla. La función \texttt{suspend} detiene la ejecución iterativa. Mediante estas funciones el sistema puede inicializar nuevos esquemas, unos esquemas pueden detener y relanzar a otros, etc..

%comunicación a través de variables
Cada esquema comunica sus resultados continuamente a través de unas variables (variables de salida) que él refresca, recoge continuamente los resultados de otros esquemas (de los cuales puede depender) a través de otras variables (variables de entrada) y admite cierta modulación en su propio funcionamiento a través de otras variables (variables de modulación) que otros esquemas pueden escribir. Las variables de entrada de un esquema pueden ser variables perceptivas de la plataforma o variables de salida de otros esquemas. Las variables de salida de un esquema pueden ser variables de actuación de la plataforma, variables de entrada para otros esquemas o variables de modulación para otros esquemas.

%condiciones de carrera
En el acceso a esas variables, así como a las variables perceptivas y de actuación que ofrece la plataforma, pueden presentarse condiciones de carrera, pues hay varios hilos de ejecución accediendo concurrentemente a ellas. Por ejemplo, la plataforma actualiza (escribe) una variable perceptiva y cuando va por la mitad otro esquema la lee. Una condición de carrera de este estilo se puede apreciar en la captura y visualización de las imágenes que son mezcla de la actual y la anterior. Estas condiciones de carrera pueden desembocar en que en una iteración un esquema no tenga buenos datos de entrada o no envíe buenas órdenes a los actuadores, pero no son muy dañinas porque enseguida llega la iteración siguiente que muy probablemente funcione de manera correcta. Dado su carácter esporádico y el planteamiento continuo de \textit{jde.c} no son muy preocupantes. Salvo casos delicados, hemos decidido no evitarlas con semáforos para no ralentizar la ejecución del sistema. 

%esqueleto de esquema: thread, iteration y cycle
\begin{table}
\begin{center}
\small
\begin{tabular}{|p{10cm}|}
\hline
  for(;;)\\
    \{\\
      pthread\_mutex\_lock(\&mymutex[SCH\_MYSCHEMA]);\\
      if (state[SCH\_MYSCHEMA]==slept)\\
        \{\\
          pthread\_cond\_wait(\&condition[SCH\_MYSCHEMA],\&mymutex[SCH\_MYSCHEMA]);\\
        \}\\
      else\\
        \{\\
          gettimeofday(\&a,NULL);\\
          myschema\_iteration();\\
          gettimeofday(\&b,NULL);\\
\\
          diff = (b.tv\_sec-a.tv\_sec)*1000000+b.tv\_usec-a.tv\_usec;\\
          next = myschema\_cycle*1000-diff-10000;\\
          /* discounts 10ms taken by calling usleep itself */\\
          if (next>0) usleep(myschema\_cycle*1000-diff);\\
          else \{printf(\"time interval violated: myschema-n\"); \\
	    usleep(myschema\_cycle*1000);\}\\
        \}\\
      pthread\_mutex\_unlock(\&mymutex[SCH\_MYSCHEMA]);\\
    \}\\
\hline
\end{tabular}
\end{center}
\normalsize
\caption{Esqueleto (\texttt{myschema\_thread}) de un esquema ejemplo proporcionado por \textit{jde.c}}
\label{tabla:esqueletoesquema}
\end{table}

\vspace{0.5cm}
Cada esquema tiene una hebra asociada que ejecuta un esqueleto de código como el de \texttt{myschema\_thread}, mostrado en la tabla \ref{tabla:esqueletoesquema}. En ese esqueleto hay un bucle infinito y en cada pasada del bucle se ejecuta una iteración del esquema, contenido en la función \texttt{myschema\_iteration}. Mediante esperas controladas con \texttt{usleep}, se domina el ritmo al que se ejecutan las iteraciones del esquema. Más allá de este esqueleto, que proporciona la plataforma \textit{jde.c}, el programador de aplicaciones debe escribir en \texttt{myschema\_iteration} el código genuino del esquema, el que resuelve su tarea concreta.

La variable \texttt{myschema\_cycle} es un ejemplo de variable de modulación, que afecta al funcionamiento del esquema (en este caso el ritmo de su ejecución) y que puede ser modificada por otros esquemas durante la ejecución. De esa manera el esquema que modifica esa variable de modulación puede conseguir que \texttt{myschema} ejecute rápidamente durante cierto tiempo y más pausadamente, a menor frecuencia, en otro.

\subsection{Aplicación con un esquema}

%partimos de una hebra sin el corsé de los esquemas.
En el caso más sencillo la aplicación robótica consta de una única hebra, por ejemplo una que materializa un bucle infinito en el cual (1) se leen datos de algunas variables sensoriales, (2) se deciden reactivamente los comandos adecuados para reaccionar ante esa situación y (3) éstos se escriben en las variables de actuación pertinentes.

El modo natural de encajar esto en un esquema es programar que en cada iteración del esquema se realicen esos tres pasos, hacer coincidir cada iteración del esquema con una iteración del buble reactivo. Una ventaja es que el ritmo de ejecución del esquema está controlado por la plataforma, de manera que se puede conseguir que ejecute a 10 iteraciones por segundo si con eso resulta suficiente para la aplicación, o a 20 si es necesario. De esta manera no se dedica más tiempo de CPU al esquema que el necesario para la naturaleza aplicación, haciendola más eficiente. Otra ventaja es que al encapsular en un esquema, éste es detenible y este esquema se puede detener sin necesidad de abortar toda la aplicación.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=9cm]{figs/appunesquema}
\end{center}
\caption{Aplicación con un único esquema}
\label{fig:aplicacion-un-esquema}
\end{figure}


%ejemplo de esquema navegación controlada por posición 
Por ejemplo, queremos que el robot se mueva en dos circulos yuxtapuestos, describiendo la figura de un ocho. Esto se puede conseguir con un único esquema que materializa un control basado en posición: lee los datos de posición y ordena las velocidades de giro y avance oportunas. En particular con un autómata de estados. 

%ejemplo de esquema navegación reactiva alejandose de obstáculos, vff

%no hay magia: sensores y actuadores
El programa que controla el comportamiento del robot sólo percibe la realidad a través de las medidas sensoriales crudas. Las decisiones han de ser expresadas como comandos a los actuadores. Precisamente la aplicación enlaza unas cosas con otras, no hay magia. 

\subsection{Aplicación con varios esquemas al mismo nivel}

El planteamiento anterior, con un \textit{único} esquema, es suficiente para aplicaciones robóticas relativamente simples, como los comportamientos reactivos, donde el robot sólo tiene que hacer una tarea y la información adecuada ya se encuentra directamente accesible en los datos sensoriales crudos. Sin embargo, cuando el robot tiene que estar pendiente de varios estímulos, o los estímulos subyacen en los datos sensoriales pero no directamente sino que necesitan cierto procesamiento, o cuando la actuación se puede agrupar en distintos modos o fases diferenciadas, etc. entonces puede resultar conveniente utilizar \textit{varios} esquemas para programar la aplicación robótica que genera el comportamiento del robot.

%esquemas perceptivos y esquemas de actuación
Cuando se van a utilizar varios esquemas en la aplicación, \textit{jde.c} distingue entre \textit{esquemas perceptivos} y \textit{esquemas de actuación}. Los esquemas perceptivos tienen como tarea buscar o construir un cierto estímulo perceptivo desde las lecturas sensoriales o desde la información elaborada por otros esquemas perceptivos. Los esquemas de actuación toman decisiones de control y tienen como tarea conseguir cierto comportamiento. 

%percepción como colección de estímulos
La percepción en \textit{jde.c} se entiende como un conjunto dinámico de estímulos. Cada estímulo es elaborado por un esquema perceptivo y se almacena en sus variables de salida, que los esquemas de actuación que lo necesitan toman como variables de entrada. El esquema perceptivo se encarga, cuando es activado, de mantener esas variables actualizadas y en correspondencia con la realidad, que es dinámica.

%actuación
Los esquemas de actuación toman sus decisiones de control a partir de los estímulos, son toda la información que tienen para ello. Sus decisiones se expresan como valores concretos para las variables de actuación, que ellos toman como sus variables de salida.

En el fichero de configuración, también se determinan los esquemas que se van a arrancar. Su activación posterior depende de las condiciones de activación y la situación del entorno del robot. En el fichero de configuración también se pueden activar trazas de depuración, por cada esquema.


\begin{figure}[htb]
\begin{center}
\includegraphics[width=9cm]{figs/appunnivel}
\end{center}
\caption{Aplicación con varios esquemas en el mismo nivel}
\label{fig:aplicacion-un-nivel}
\end{figure}


Especialistas de actuación = varios esquemas de actuación, cada uno con sus precondiciones.

Estímulos más elaborados que las simples lecturas sensoriales= esquemas perceptivos, unos toman las salidas de otros, construyendo estímulos más complejos. Típico en visión.

%ejemplo: robot sigue persona con vision (sin cuello mecánico)

\subsection{Aplicación con jerarquía de esquemas}

Las aplicaciones con un esquema o con un conjunto de ellos en el mismo nivel se pueden catalogar como programación sencilla con \textit{jde.c}. La programaciónde  aplicaciones robóticas con una jerarquía dinámica de esquemas se podría encajar en programación avanzada con \textit{jde.c}, en la cual se usan mecanismos de arbitraje, monitorización contínua, precondiciones, etc. relativamente complejos y potentes.

\begin{figure}
\begin{center}
\includegraphics[width=6cm]{figs/appjerarquia}
\end{center}
\caption{Aplicación robótica implementada con una jerarquía dinámica de esquemas}
\label{fig:app-jerarquia}
\end{figure}

%jerarquía
Unos esquemas utilizan las variables que otros actualizan. También los esquemas pueden activar y modular a otros para que materialicen el comportamiento que le interesa. La plataforma materializa la arquitectura cognitiva Jerarquía Dinámica de Esquemas \cite{canas03} para la generación de comportamientos en robots móviles. 
Para poder combinar varias 
 puede constar de varias hebras y para comportamientos complejos es necesario organizar la ejecución de esas hebras de modo jerárquico.

\section{Interfaz gráfica de la aplicación robótica}


\subsection{Guixforms}

Además, una hebra adicional, llamada \texttt{guixforms}, se encarga de mantener la interfaz gráfica de la aplicación robótica. Para ello refresca periódicamente la salida gráfica y muestrea las acciones del usuario humano en el frontal de la aplicación (picar con el ratón, pulsar botón visual, etc.).

Ritmo controlado, hebra separada. XForms
3. Las aplicaciones que corren a bordo de los robots deben encargarse también de su interfaz gráfica. Aunque la interfaz gráfica no es indispensable para generar y materializar el comportamiento autónomo en el robot, normalmente resulta muy útil como herramienta de depuración. Además de las posibilidades de interacción con el usuario, la interfaz gráfica permite la visualización en tiempo de ejecución de estructuras y variables internas (e.g. representaciones del mundo, mapas, estados, etc.). 


\begin{figure}
\begin{center}
\includegraphics[width=9cm]{figs/jdesample}
\end{center}
\caption{Interfaz gráfica mantenida por el esquema \texttt{guixforms}}
\label{fig:gui}
\end{figure}

\textit{Esquema guixforms} En la interfaz se refrescan periódicamente las estructuras internas como las medidas sensoriales o las variables que reflejan cierto estímulo percibido. Desde la interfaz se pueden activar y desactivar a voluntad varios esquemas.

\textit{Teleoperator de la base} Teleoperación de la plataforma móvil.

\textit{Pantiltjoystick} Teleoperación del cuello mecánico.

Depuración de variables perceptivas.


Se le incorpora

\subsection{Adaptando la interfaz gráfica}

¿Cómo pintar una recta en el canvas? ¿Como pintar un punto en el canvas? ¿Cómo recibir el click del ratón en el canvas? ¿Cómo recibir el click del ratón en una imagen? ¿Cómo visualizar imágenes?

De coordenadas gráficas GUI a posición en el mundo. Viceversa
De coordenadas gráficas GUI a píxel en imagen. Vicevers.

\section{Instalación}

\subsection{Descripción de las aplicaciones}
\subsubsection{Aplicaciones propias}
Actualmente tenemos varias aplicaciones desarrolladas por nosotros mismos, las cuales pueden ser descargadas desde la página web oficial:

\vspace{5 mm}

\texttt{http://gsyc.escet.urjc.es/jmplaza/research-arch.html\#jde.c}

\vspace{5 mm}

\begin{enumerate}
\item
\texttt{jde.c} -- Es el programa principal. Desde \texttt{jde.c} tendremos fácil acceso a los recursos del robot, y con él podremos añadir nuestros esquemas.
\item
\texttt{otos} -- \texttt{Otos} es el servidor encargado del acceso a los sensores, sónares, laser y ruedas, entre otras cosas. Incluye así mismo el cliente de prueba \texttt{otosclient}
\item
\texttt{oculo} -- \texttt{Oculo} es el servidor que nos permite acceder a la visión del robot, incluyendo cámaras usb o firewire, y la unidad pantilt.
\item
\texttt{hsituner} -- Con esta aplicación podremos seleccionar fácilmente rangos de color en el espacio hsi conectándonos a un servidor oculo.
\end{enumerate}
\subsubsection{Third party}
\begin{enumerate}
\item
libAria -- Ésta es la biblioteca con la que accedemos al robot Pioneer. Pese a ser GPL (esto es, software libre), no están disponibles de forma libre. Se permite su distribución y modificación,
pero Activemedia, el fabricante, no permite descargarlo de forma libre desde su página web. Por tanto, si deseas una copia del código debes ponerte en contacto con el grupo de robótica.
\item
player/stage -- Es uno de los simuladores que utilizamos para poder modelar un mundo virtual en el que se sitúe el robot.
\item
firewire -- Son una serie de bibliotecas necesarias para programar aplicaciones que accedan directamente a cámaras firewire, como por ejemplo iSight, las que a menudo usamos con los robot Pioneer.
\item
libforms -- Actualmente las aplicaciones tienen su interfaz desarrollada con estas bibliotecas gráficas. Si lo deseas, también puedes instalarte libforms-bin, que son un conjunto de aplicaciones que permiten desarrollar de forma muy intuitiva una interfaz gráfica con estas bibliotecas.
\item
Otros -- También utilizamos más bibliotecas dinámicas propias del kernel de Linux, como por ejemplo libpthread, libm, libdl, libstdc, etc.
\end{enumerate}
\subsection{Instalación del binario en Debian/Ubuntu}
\label{apt}
Con este método podremos instalar sencillamente todos los paquetes ya compilados y listos para funcionar en nuestro sistema.
\begin{enumerate}
\item
Actualizar \texttt{/etc/apt/sources.list} -- Para poder instalar los binarios debemos añadir dos nuevos repositorios a nuestro \texttt{/etc/apt/sources.list}:
\begin{verbatim}
deb http://veo.dat.escet.urjc.es/debian dist main
deb-src http://veo.dat.escet.urjc.es/debian dist main\end{verbatim}
Sustituyendo \emph{dist} por tu versión, por ejemplo \emph{sarge} o \emph{breezy}.
\item
Actualizar lista de paquetes -- Ahora actualizamos la copia local de la lista de paquetes ejecutando:

\texttt{apt-get update}
\item
Y finalmente instalamos el entorno de desarrollo y la plataforma completa:

\texttt{apt-get install robotica robotica-dev}
\end{enumerate}

\subsection{Instalación desde el código fuente}
Si tu intención es programar y/o modificar el código fuente de alguna de las aplicaciones del entorno, entonces deberás poder instalarla a partir del código fuente. A continuación están las instrucciones para cada una de ellas.
\subsubsection{jde.c -- 3.4}
Para poder compilar necesitas tener instaladas unas determinadas bibliotecas de desarrollo. En concreto son las siguientes:

\vspace{5 mm}

\texttt{libpthread, libforms, libX11, libm}

\vspace{5 mm}

Todas ellas son estándar, y se puede instalar fácilmente desde cualquier distribución.

Ahora debemos descomprimir el tar.gz:

\vspace{5 mm}

\texttt{tar xzf jde-3.4.tgz}

\vspace{5 mm}

Si no usas Debian o Ubuntu, entonces es posible que debas modificar el fichero \texttt{makefile} para que asegurarte de que \texttt{INC-DIR} y \texttt{LIB-DIR} apunten a los sitios correctos.

Por último, ejecuta \texttt{make} para generar el binario.
\subsubsection{Otos -- 5.3}
Para compilar otos necesitamos las siguientes bibliotecas:

\vspace{5 mm}

\texttt{libpthread, libforms, libX11, libm, libdl, libstdc++, libAria}

\vspace{5 mm}

Todas ellas son estándar y se puede instalar fácilmente, a excepción de libAria. Si necesitas instalar libAria lo más sencillo es hacerlo con apt desde el repositorio de robótica (Ver apartado \ref{apt}) ejecutando:

\vspace{5 mm}

\texttt{aptitude install aria-robot aria-robot-dev}

\vspace{5 mm}

Importante: Para poder compilar otos es \emph{necesario} utilizar la versión 3.3 tanto de gcc como de g++. Para ello debes instalarlo, y actualizar el \texttt{makefile} para que utilize \texttt{gcc-3.3} y \texttt{g++-3.3}. Ya sólo nos queda compilarlo:

\vspace{5 mm}

\texttt{make}

\subsubsection{Otos con soporte para player/stage -- 1.4rc2}
Otos podemos compilarlo también con soporte para player/stage. Para ello debemos tener player instalado y si fuera necesario tendríamos que modificar \texttt{makefile} para poder enlazar correctamente con la biblioteca de player. Para instalarlo lo más sencillo es hacerlo desde apt:

\vspace{5 mm}

\texttt{aptitude install player stage}

\vspace{5 mm}

Alternativamente también podríamos instalarlo desde el código fuente original. Para ello nos dirigimos a la página del desarrollador y descargamos el tarball de la versión 1.4rc2 y seguimos las siguientes instrucciones:

\begin{verbatim}
tar xzf player-src-1.4rc2.tar.gz
cd player-src-1.4rc2
./configure --disable-cmvision --bindir=/usr/bin \
--includedir=/usr/include --libdir=/usr/lib
make
make install\end{verbatim}

Finalmente, para decirle a otos que se compile compile con soporte para player, debemos ejecutar:

\vspace{5 mm}

\texttt{make psg}

\vspace{5 mm}
\subsubsection{Oculo -- 3.10}
Para compilar oculo necesitamos las siguientes bibliotecas de desarrollo:

\vspace{5 mm}

\texttt{libpthread, libXext, libX11, libm, libdc1394, libraw1394}

\vspace{5 mm}

Todas estas bibliotecas son estandar, por lo que podremos instalarlas cómodamente desde cualquier distribución.

Si fuera necesario, modificaríamos las rutas a las bibliotecas en las variables \texttt{INC-DIR} y en \texttt{INC-LIB} de \texttt{makefile}.

Finalmente, para compilarlo ejecutamos

\vspace{5 mm}

\texttt{make}

\subsubsection{hsituner -- 2.1}
hsituner depende de las siguientes bibliotecas:

\vspace{5 mm}

\texttt{libpthread, libforms, libX11, libm}

\vspace{5 mm}
Y para compilar sencillamente ejecutamos:

\vspace{5 mm}

\texttt{make}

\subsection{Configuración}
La configuración de jdec se especifica en un fichero de texto plano
(normalmente con extensión .conf) que indica qué drivers se desean
cargar con la plataforma y qué esquemas desean utilizarse.\\

Por defecto, el fichero de configuración utilizado es
\textit{jde.conf}, el cual se encuentra ubicado en el directorio de
configuración de jdec (dependiendo de si se ha instalado mediante
paquetes o compilado directamente puede variar).\\

Los esquemas que se desean cargar se especifican indicando la palabra
\textit{load} seguida del nombre del esquema. Este debe ser
previamente compilado y ubicado en el directorio de módulos dinámicos
de la plataforma (depende del tipo de instalación que se haya
seguido).\\

Un ejemplo de carga de esquemas es el siguiente:
\begin{verbatim}
...
load myschema
load opengldemo
load perceptive1
...
\end{verbatim}

El nombre indicado que se desea cargar debe concidir con el nombre del
fichero binario precompilado. En este caso, \textit{load myschema}
buscará un archivo binario llamado \textit{myschema.so}.\\

De igual forma, los drivers que se desean cargar deben estar
previamente compilados y ubicados en el directorio de módulos
dinámicos de la aplicación (depende del tipo de instalación que se
haya utilizado).\\

La forma de especificar que se desea cargar un determinado driver es
la siguiente:

\begin{verbatim}
...
driver <nombre_driver>
<parametros_configuracion_driver>
end_driver
...
\end{verbatim}

A continuación se indica cómo cargar cada uno de los drivers de
jdec y después se incluye un ejemplo de fichero de configuración:

\subsubsection{Driver player}
El driver \textit{player} permite a jdec conectarse a un servidor
Player que le transmitirá las medidas recabadas de las informaciones sensoriales de un
robot o de un simulador.\\

Para cargar este driver, el fichero de configuración de jdec debe
contener estas líneas:

\begin{verbatim}
driver player
hostname <nombre_maquina> port <numero_puerto>
initial_position <coordenada_x> <coordenada_y> <orientacion_theta>
provides laser
provides sonars
provides encoders
provides motors
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{hostname y port}: indican el nombre de máquina o
  dirección IP, y el puerto donde se encuentra lanzado el servidor
  Player.
\item \textit{provides}: indica qué dispositivos del robot se desean
  utilizar. Cada dispositivo utilizado debe ir en una nueva línea. No
  es obligatorio usar todos.
\item \textit{initial position}: indica la posición inicial del robot
  en el mundo de coordenadas relativas de jdec. Se precisa una
  posición X, una posición Y y una orientación en radianes Theta. No
  es obligatorio utilizar esta opción.
\end{itemize}

\subsubsection{Driver pantilt}
El driver \textit{pantilt} permite a jdec conectarse a un cuello
mecánico Pantilt local y transmitirle órdenes de movimiento a los motores y
recibir la información de sus sensores de posición.\\

Este driver se puede cargar mediante la siguiente configuración:

\begin{verbatim}
driver pantilt
serial <serial_port>
provides pantiltencoders
provides pantiltmotors
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{serial}: indica el dispositivo serie en el que está
  conectado el cuello mecánico, por ejemplo \textit{/dev/ttyUSB0}.
\item \textit{provides}: indica qué dispositivos del cuello se desean
  utilizar. Cada dispositivo utilizado debe ir en una nueva línea. No
  es obligatorio usar todos.
\end{itemize}

\subsubsection{Driver video4linux}
Permite a jdec conectarse a cámaras USB locales mediante la interfaz
\textit{video4linux}. Para cargar este driver se debe utilizar una configuración del
siguiente estilo:

\begin{verbatim}
driver video4linux
provides colorA <dispositivo_video_0>
provides colorB <dispositivo_video_1>
provides colorC <dispositivo_video_2>
provides colorD <dispositivo_video_3>
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{provides}: indica los dispositivos de imágenes que se
  desean utilizar. Para cada dispositivo se debe indicar la ruta a su
  fichero video4linux, como por ejemplo \textit{/dev/video0}. Cada
  dispositivo utilizado debe ir en una nueva línea. No es obligatorio usar todos.
\end{itemize}

\subsubsection{Driver firewire}
Permite a jdec conectarse a cámaras firewire locales mediante la
interfaz \textit{libdc1394}. Para cargar este driver se debe utilizar una configuración del
siguiente estilo:

\begin{verbatim}
driver firewire
provides colorA <numero_camara> <autofocus_option>
provides colorB <numero_camara> <autofocus_option>
provides colorC <numero_camara> <autofocus_option>
provides colorD <numero_camara> <autofocus_option>
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{provides}: indica los dispositivos de imágenes que se
  desean utilizar. Para cada dispositivo se debe indicar el número de
  cámara dentro del bus firewire (0,1,2...). Actualmente, jdec sólo
  soporta la conexión de dos cámaras firewire locales
  simultáneamente. Cada dispositivo utilizado debe ir en una nueva línea.
\item \textit{autofocus option}: para cada dispositivo inicializado se
  puede indicar mediante las opciones \textit{autofocus on} o
  \textit{autofocus off} si se desea activar o desactivar la función
  autofocus que permiten algunas cámaras firewire.
\end{itemize}

\subsubsection{Driver imagefile}
Permite la carga de imágenes estáticas para suplantar las imágenes de
una cámara. Hasta ahora, los formatos de imágenes soportados deben
tener extensión \textit{.pnm} o bien \textit{.ppm}, con una resolución
máxima de 320x240 píxeles. Para convertir imágenes a estos formatos se
puede utilizar la aplicación de diseño gráfico \textit{Gimp}\footnote{http://www.gimp.org}.\\

La carga de este driver se realiza de la siguiente manera:

\begin{verbatim}
driver imagefile
provides colorA <path_fichero>
provides colorB <path_fichero>
provides colorC <path_fichero>
provides colorD <path_fichero>
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{provides}: indica los dispositivos de imágenes que se
  desean utilizar. Para cada dispositivo se debe indicar el path al
  fichero. Cada dispositivo utilizado debe ir en una nueva línea. No es obligatorio usar todos.
\end{itemize}

\subsubsection{Driver networkserver}
El driver \textit{networkserver} permite a jdec servir mediante una
conexión \textit{TCP/IP} todos los dispositivos que pueda tener
conectados. Entre estos se incluye cualquier cámara o imagen estática
configurada, los dispositivos del robot o un cuello mecánico.\\

El acceso a los dispositivos se puede realizar en una red local o
através de internet. Mediante este driver, jdec se puede utilizar como
un servidor de imágenes o de dispositivos de un robot.\\

La configuración que permite iniciar este driver es la siguiente:

\begin{verbatim}
driver networkserver
socket <numero_puerto>

#images section
serves colorA <identificador_red_0>
serves colorB <identificador_red_1>
serves colorC <identificador_red_2>
serves colorD <identificador_red_3>

#pantilt section
serves pantiltencoders
serves pantiltmotors

#robot section
serves laser
serves sonars
serves encoders
serves motors
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{serves}: indica los dispositivos que se
  desean servir. Cada dispositivo utilizado debe ir en una nueva
  línea. No es obligatorio usar todos. En el caso de los dispositivos
  de imágenes, se debe indicar además su identificador de imagen. De
  esta forma, el receptor puede elegir qué imagen quiere leer. Si
  alguno de los dispositivos servidos no ha sido previamente
  inicializado, este driver enviará datos inválidos.
\item \textit{socket}: indica el número de puerto en el que se atará
  el servidor del driver, y en el que podrá recibir peticiones.
\end{itemize}

\subsubsection{Driver networkclient}
El driver \textit{networkclient} permite a jdec conectarse a otro jdec
que esté usando el driver \textit{networkserver} para servir algún
dispositivo. Mediante \textit{networkclient} se puede también
conectarse a un servidor \textit{otos} o \textit{oculo}, según el tipo
de dispositivo utilizado.

La conexión \textit{TCP/IP} es válida en una red local o através de
internet. La configuración que permite iniciar este driver es la siguiente:

\begin{verbatim}
driver networkclient
#images section
provides colorA <nombre_maquina> <numero_puerto> <identificador_red_0>
provides colorB <nombre_maquina> <numero_puerto> <identificador_red_1>
provides colorC <nombre_maquina> <numero_puerto> <identificador_red_1>
provides colorD <nombre_maquina> <numero_puerto> <identificador_red_1>

#pantilt section
provides pantiltencoders <nombre_maquina> <numero_puerto>
provides pantiltmotors <nombre_maquina> <numero_puerto>

#robot section
initial_position <coordenada_x> <coordenada_y> <orientacion_theta>
provides laser <nombre_maquina> <numero_puerto>
provides sonars <nombre_maquina> <numero_puerto>
provides encoders <nombre_maquina> <numero_puerto>
provides motors <nombre_maquina> <numero_puerto>
end_driver
\end{verbatim}

\begin{itemize}
\item \textit{provides}: indica qué dispositivos se desean utilizar y
  a los que se conectará el driver. Cada dispositivo utilizado debe ir
  en una nueva línea. No es obligatorio usar todos. Para cada
  dispositivo se debe indicar el nombre de la máquina o la dirección
  IP y el puerto donde se encuentra el servidor. En el caso de las
  imágenes, también es necesario indicar el identificador de la misma.
\item \textit{initial position}: indica la posición inicial del robot
  en el mundo de coordenadas relativas de jdec. Se precisa una
  posición X, una posición Y y una orientación en radianes Theta. No
  es obligatorio utilizar esta opción.
\end{itemize}

\subsubsection{Fichero de configuración de ejemplo}
Este es un posible archivo de configuración de jdec. En él se puede
ver una configuración de carga de drivers y esquemas.\\

Nótese que mediante el símbolo almohadilla se pueden comentar líneas
de texto:

\begin{verbatim}
### DRIVER LOAD FOR SENSOR SOURCES AND MOTOR DEVICES  -------------------
driver firewire
provides colorA 0 autofocus_off
provides colorB 1 autofocus_on
end_driver

#driver imagefile
#provides colorA /usr/local/share/jde-robot/casaleft.pnm
#provides colorB /usr/local/share/jde-robot/atardecer.ppm
#provides colorC /usr/local/share/jde-robot/atardecer.ppm
#provides colorD /usr/local/share/jde-robot/casaright.pnm
#end_driver

#driver video4linux
#provides colorA /dev/video0
#end_driver

driver player
hostname localhost port 6665
initial position X(mm) Y(mm) Theta(deg)
initial_position -6500 -6500 45
provides laser
provides sonars
provides encoders
provides motors
end_driver

#driver pantilt
#serial /dev/ttyUSB0  
## replace with the serial port used by the pantilt unit
#provides pantiltencoders
#provides pantiltmotors
#end_driver

#driver networkclient
#images section
#provides colorA localhost 3001 0
#provides colorB localhost 3001 1
#provides colorC localhost 3002 0
#provides colorD localhost 3002 1

#pantilt section
#provides pantiltencoders localhost 3001
#provides pantiltmotors localhost 3001

#robot section
#provides laser localhost 3001
#provides sonars localhost 3001
#provides encoders localhost 3001
#provides motors localhost 3001
#end_driver

#networkserver driver must be always the last driver to be loaded
#driver networkserver
#socket 3001

#images section
#serves colorA 0
#serves colorB 1
#serves colorC 2
#serves colorD 3

#pantilt section
#serves pantiltencoders
#serves pantiltmotors

#robot section
#serves laser
#serves sonars
#serves encoders
#serves motors
#end_driver

### SCHEMA LOAD --------------------
load perceptive1
load myschema
load hsituner
load opengldemo
\end{verbatim}

\subsection{Arranque de la plataforma y shell interno}
Para lanzar jdec, una vez completados los pasos de instalación y
configuración, se realiza ejecutando el archivo binario \textit{jde}.\\

Si se ejecuta con la opción \textit{--help}, la plataforma indica las
opciones de arranque:

\begin{verbatim}
$./jde --help
JDE 4.2
Use: jde [config.file] [--gui]

     [config.file] Sets an specific config file. Don't use this option
                   to read default configuration.
           [--gui] Starts JDE with the main gui activated.

\end{verbatim}

Una vez arrancada la aplicación, si se desea, se puede utilizar la
consola proporcionada para ejectuar órdenes sencillas. Se puede
obtener un listado de opciones tecleando el comando \textit{help}.

\begin{verbatim}
JDEC >> help
This is the shell of JDE 4.2. Available commands are:
  quit
  mastergui [on|off]
  sensorsmotorsgui [on|off]

\end{verbatim}

\subsection{Cuadro resumen de aplicaciones y dependencias}
\begin{center}
\begin{tabular}{|l|l||l||l|l|}
\hline
Aplicación  & Versión      & Compiladores válidos  & Dependencias    & Versión   \\
\hline
jde.c       & 3.4          & gcc-4.0               & libforms        &           \\
            &              & gcc-3.3               & libX11          &           \\
            &              & gcc-2.95              & libm            &           \\
            &              &                       & libpthread      &           \\
\hline
otos        & 5.3          & gcc-4.0 y g++4.0      & libpthread      &           \\
            &              &                       & libforms        &           \\
            &              &                       & libX11          &           \\
            &              &                       & libm            &           \\
            &              &                       & libdl           &           \\
            &              &                       & libstdc++       &           \\
            &              &                       & libAria         & 1.3.2     \\
            &              &                       & libplayerc *    & 1.4rc2    \\
\hline
oculo       & 3.10         & gcc-4.0               & libpthread      &           \\
            &              & gcc-3.3               & libXext         &           \\
            &              & gcc-2.95              & libX11          &           \\
            &              &                       & libm            &           \\
            &              &                       & libdc1394       &           \\
            &              &                       & libraw1394      &           \\
\hline
hsituner    & 2.1          & gcc-4.0               & libforms        &           \\
            &              & gcc-3.3               & libm            &           \\
            &              & gcc-2.95              & libpthread      &           \\
\hline
\end{tabular}
\end{center}
* libplayerc es opcional

\section{Biblioteca de esquemas}

%el planteamiento de esta sección, de momento, es describir brevemente y dar punteros a los pfcs donde se describen en detalle las técnicas, los algoritmos y los esquemas programados.

%filtro de color, vff, segmentación histográmica recursiva, segmentación lineal, memoria laser, etc.

A continuación se describen los esquemas disponibles actualmente en la plataforma. Se recomienda utilizarlos para crear nueva funcionalidad sobre la suya.

Muchos son los comportamientos desarrollados en robots con \textit{jde.c}, tanto en docencia, en proyectos fin de carrera y en las investigaciones científicas. Ese uso ha ido generando una colección de esquemas que encapsulan funcionalidad interesante. Reutilizar no es inmediato. De hecho, reutilizar en plan caja negra sin retocar nada, es casi imposible, sólo viable en casos muy claros. Sin embargo, el conjunto de esquemas sí ofrecen muchos algoritmos y líneas de código que con algo de estudio, adaptación, afinación se pueden reutilizar en nuevas aplicaciones, acortando el tiempo de desarrollo.

%sólo las cosas muy probadas.

%\subsection{Navegación con obstáculos locales}
%\subsubsection{Esquema lasersegments}
%\subsubsection{Esquema occupancygrid}
%\subsubsection{Esquema followwall}

%\subsection{Procesamiento visual}
%\subsubsection{Esquema edges}
%\subsubsection{Esquema visualdiff}
%\subsubsection{Esquema visualjamb}
%\subsubsection{Esquema jambgrid}

%\subsection{Navegación hacia un punto cercano}
%\subsubsection{Esquema advance}
%\subsubsection{Esquema gotopoint}
%\subsubsection{Esquema stop}

\section{Utilidades}

\subsection{Clientes de prueba}
otosclient, oculoclient, stereoclient.
\subsection{hsituner}
%\subsection{fuzzylib}
%\subsection{gridslib}
%\subsection{progeo}

\section*{Contribuidores}
%quién ha hecho qué

Aunque \textit{jde.c} nació en 1997 como la plataforma software de una tesis doctoral, hace tiempo que dejó de ser el esfuerzo de una única persona. La plataforma \textit{jde.c} ha servido de infraestructura software para muchos alumnos en sus proyectos de fin de carrera \cite{canas05a,canas05b,canas05c,canas06b}, simplificándoles la programación del robot. De esta manera se convirtieron en usuarios y en sus \textit{beta-testers}. Más allá de un amplio conjunto de usuarios, un selecto grupo de desarrolladores la mantiene y amplía su funcionalidad. Contribuciones relevantes a este manual se deben a alumnos del grupo de robótica de la URJC. 

\begin{itemize}
\item Pablo Barrera: empaquetador
\item Roberto Calvo: soporte cámaras video4linux con driver comprimido
\item Carlos Castillo: soporte de Gazebo
\item Ivan García: opengl en XForms
\item Victor Gómez: esquema lasersegments
\item Raul Isado: esquema visualdiff, soporte de Stage
\item David Lobato: soporte firewire
\item Antonio Pineda: soporte firewire, mantenedor oficial
\item Jesús Ruiz-Ayúcar: empaquetador, GTK
\end{itemize}

\textit{jde.c} es un proyecto vivo que evoluciona. Ahora mismo hay varias líneas en las que estamos trabajando: la incorporación de opengl para visualizar 3d y la sustitución de XForms por GTK.

\nocite{*}
%\bibliographystyle{alpha}
\bibliography{jdecmanual}

%otras plataformas
%manuales de pantilt, base pioneer
%pfcs hechos con jde

\end{document}

